{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7015a26-b749-4526-805a-3cf50c01ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"data/final_output/final_output2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f91888b-8ced-44e4-b57f-3ac8d386141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def score_results(data):\n",
    "\n",
    "    # Create score system\n",
    "    output = pd.DataFrame(data['DOI'])\n",
    "\n",
    "    # init count col\n",
    "    output['Count'] = 0\n",
    "    \n",
    "    ## MNLI score threshold of 0.7\n",
    "    output['Count'] += (data['BART_MNLI_Score'] >= 0.7).astype(int)\n",
    "\n",
    "    output['Score'] = data['BART_MNLI_Score']\n",
    "\n",
    "    ## Organization check\n",
    "    target_orgs = {\n",
    "        'Radboud University Nijmegen',\n",
    "        'Radboud University Medical Center',\n",
    "        'Radboud Institute for Molecular Life Sciences'\n",
    "    }\n",
    "\n",
    "    def to_list_safe(x):\n",
    "        \"\"\"Convert stringified list to Python list safely.\"\"\"\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "        return ast.literal_eval(x)\n",
    "\n",
    "    def org_check(orgs):\n",
    "        return int(any(org in target_orgs for org in orgs))\n",
    "\n",
    "    # First author\n",
    "    output['Count'] += data['First_Author_Organization'].apply(\n",
    "        lambda x: org_check(to_list_safe(x))\n",
    "    )\n",
    "    output['First_author'] = data['First_Author_Organization'].apply(\n",
    "        lambda x: org_check(to_list_safe(x)) > 0\n",
    "    )\n",
    "\n",
    "    # Last author\n",
    "    output['Count'] += data['Last_Author_Organization'].apply(\n",
    "        lambda x: org_check(to_list_safe(x))\n",
    "    )\n",
    "    output['Last_author'] = data['Last_Author_Organization'].apply(\n",
    "        lambda x: org_check(to_list_safe(x)) > 0\n",
    "    )\n",
    "\n",
    "    ### Mesh\n",
    "    ## Animals_used\n",
    "    output['Count'] += (data['Animals_Used']).astype(int)\n",
    "\n",
    "    output['Animals_Used_MesH'] = data['Animals_Used']\n",
    "\n",
    "    ## In_vivo\n",
    "    output['Count'] += (data['In_Vivo']).astype(int)\n",
    "\n",
    "    output['In_Vivo_MesH'] = data['In_Vivo']\n",
    "\n",
    "    #### GPT\n",
    "    ## Animals_used\n",
    "    output['Count'] += (data['animal_testing'] == 'yes').astype(int)\n",
    "\n",
    "    output['Animals_Used_GPT'] = (data['animal_testing'] == 'yes')\n",
    "\n",
    "    ## In_vivo\n",
    "    output['Count'] += (data['in_vivo'] == 'yes').astype(int)\n",
    "\n",
    "    output['In_Vivo_GPT'] = (data['in_vivo'] == 'yes')\n",
    "    \n",
    "    # Location\n",
    "    output['Count'] += data['location'].str.contains('radboud|nijmegen', case=False, na=False).astype(int)\n",
    "    output['Location_Radboud'] = data['location'].str.contains('radboud|nijmegen', case=False, na=False)\n",
    "    output['Location'] = data['location']\n",
    "\n",
    "    # Approving org\n",
    "    output['Count'] += data['approving_organization'].str.contains('radboud|nijmegen|netherlands', case=False, na=False).astype(int)\n",
    "    output['Apr_org_netherlands'] = data['approving_organization'].str.contains('radboud|nijmegen|netherlands', case=False, na=False)\n",
    "    output['Approving_organization'] = data['approving_organization']\n",
    "\n",
    "    output['Species'] = data['species']\n",
    "    \n",
    "    return output\n",
    "    \n",
    "output = score_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5712a65f-8984-4cd0-8e69-cece5bb5b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def evaluate_row(data):\n",
    "    if data['Count'] == 9:\n",
    "        return True\n",
    "    elif not data['Animals_Used_MesH'] and data['Score'] < 0.7:\n",
    "        return False\n",
    "    elif not data['In_Vivo_GPT'] or not data['Animals_Used_GPT']:\n",
    "        return False\n",
    "    elif data['Count'] == 8 and data['Location'] == 'No location mentioned':\n",
    "        return True\n",
    "    elif not data['Apr_org_netherlands'] and not data['Approving_organization'] == 'No approval mentioned':\n",
    "        return False\n",
    "    elif (not data['First_author'] and not data['Last_author'] and \n",
    "          data['Location'] == 'No location mentioned' and \n",
    "          data['Approving_organization'] == 'No approval mentioned'):\n",
    "        return False\n",
    "    elif (not data['Location_Radboud'] and not data.Location == 'No location mentioned'):\n",
    "        return False\n",
    "    elif (not data['Apr_org_netherlands'] and not data.Approving_organization == 'No approval mentioned'):\n",
    "        return False\n",
    "    elif data.Count == 7 and not data.Animals_Used_MesH and not data.In_Vivo_MesH:\n",
    "        return True\n",
    "    elif data.First_author and data.Last_author and data.Apr_org_netherlands and data.Location == 'No location mentioned':\n",
    "        return True\n",
    "    elif data.Count == 8 and data.Score < 0.7:\n",
    "        return True\n",
    "    elif data.Location_Radboud and data.Apr_org_netherlands:\n",
    "        return True\n",
    "    elif not data.First_author and not data.Last_author and not data.Location_Radboud:\n",
    "        return False\n",
    "    elif re.search(r'radboud|nijmegen', data.Approving_organization, re.IGNORECASE):\n",
    "        return True\n",
    "    elif data.First_author and data.Last_author and data.Location_Radboud and data.Approving_organization == 'No approval mentioned':\n",
    "        return True\n",
    "    elif data.First_author and data.Last_author and data.Location == 'No location mentioned' and data.Approving_organization == 'No approval mentioned':\n",
    "        return True\n",
    "    elif data.First_author and not data.Last_author and data.Location == 'No location mentioned' and data.Approving_organization == 'No approval mentioned':\n",
    "        return True\n",
    "    elif not data.First_author and data.Last_author and data.Location == 'No location mentioned' and data.Approving_organization == 'No approval mentioned':\n",
    "        return False\n",
    "    elif data.First_author and data.Location_Radboud:\n",
    "        return True\n",
    "    elif not data.First_author and not data.Last_author:\n",
    "        return False\n",
    "    elif not data.First_author and not data.Location_Radboud:\n",
    "        return False\n",
    "    elif data.Location_Radboud:\n",
    "        return True\n",
    "    elif data.First_author and data.Apr_org_netherlands:\n",
    "        return True\n",
    "    else:\n",
    "        return 99  # or some default value\n",
    "\n",
    "# Apply to your DataFrame\n",
    "output['result'] = output.apply(evaluate_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "92f1954f-e527-46ab-9404-48bf6e90a234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42659\n",
      "51664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def modify_for_tableau(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Auteur column (vectorized conditions)\n",
    "    conditions = [\n",
    "        data[\"First_author\"] & data[\"Last_author\"],\n",
    "        data[\"First_author\"],\n",
    "        data[\"Last_author\"],\n",
    "    ]\n",
    "    choices = [\n",
    "        \"Eerste en laatste auteur\",\n",
    "        \"Eerste auteur\",\n",
    "        \"Laatste auteur\",\n",
    "    ]\n",
    "    data[\"Auteur\"] = np.select(conditions, choices, default=\"Geen van beide\")\n",
    "\n",
    "    # Split on semicolon, expand into lists\n",
    "    data[\"Species\"] = data[\"Species\"].str.split(r\"\\s*;\\s*\")\n",
    "\n",
    "    # Explode into multiple rows\n",
    "    data = data.explode(\"Species\", ignore_index=True)\n",
    "\n",
    "    # Species mapping\n",
    "    species_mapping = pd.read_excel(\"species_mapping.xlsx\")\n",
    "\n",
    "    # Example: assume mapping file has \"Species\" and \"Common_Name\"\n",
    "    mapping_dict = species_mapping.set_index(\"Species\")[\"Standardized Name\"].to_dict()\n",
    "    data[\"Species\"] = data[\"Species\"].map(mapping_dict).fillna(data[\"Species\"])\n",
    "\n",
    "    #data.loc[data[\"result\"] != True, \"Species\"] = pd.NA\n",
    "\n",
    "    ## Left join publicaties\n",
    "    publicaties = pd.read_excel('data/publicaties.xlsx')\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "        # Perform left join on DOI\n",
    "    data = data.merge(\n",
    "        publicaties[[\"DOI nummer\", \"Faculteit\", \"Onderzoeksinstituut\", \"Jaar uitgave\"]],\n",
    "        how=\"left\",\n",
    "        left_on=\"DOI\",\n",
    "        right_on=\"DOI nummer\"\n",
    "    )\n",
    "\n",
    "    # Drop duplicate key column if you donâ€™t need both\n",
    "    data = data.drop(columns=[\"DOI nummer\"])\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "output = modify_for_tableau(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffa1235d-9109-4c42-ada3-55802aa19632",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[output.result == True].Species.value_counts().to_excel('Species_mapping.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08c76088-c43e-41af-8048-469f5f28c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_excel(\"data/final_output/Animal_classification.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a786f91a-faae-4a0f-9160-4a55b1b8b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.Species.value_counts().to_excel(\"Species_list.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e761f2e-10e1-4673-aaf9-d56f32a05882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.2174/1570159X21666230720122354', '10.1002/JIMD.12657', '10.3791/66457', '10.3390/D16060340', '10.1371/JOURNAL.PONE.0301459', '10.1016/J.CELREP.2023.112658', '10.1038/S41551-023-01050-0', '10.1126/SCIADV.ABQ8657', '10.1111/1365-2435.14294', '10.1093/JXB/ERAC501', '10.1016/J.SCITOTENV.2023.165212', '10.1152/AJPRENAL.00101.2022', '10.1088/1741-2552/AC6771', '10.1111/1365-2435.13966', '10.3354/MEPS14074', '10.1152/AJPLUNG.00613.2020', '10.1016/J.PNEUROBIO.2021.102069', '10.1002/JNR.24894', '10.1126/SCIENCE.ABB3356', '10.1176/APPI.AJP.2019.18050599', '10.1136/ANNRHEUMDIS-2019-216233', '10.1016/J.CELREP.2019.12.002', '10.1016/J.HELIYON.2020.E04867', '10.1007/S00726-020-02872-X', '10.1158/1078-0432.CCR-20-2255', '10.1038/S41564-020-0780-3', '10.1038/S41598-020-62039-2', '10.1096/FJ.201902901R', '10.2967/JNUMED.119.234542', '10.1073/PNAS.1901513116', '10.1096/FJ.201800907RR', '10.1039/C9BM00661C', '10.1158/2326-6066.CIR-18-0280', '10.1002/EJI.201747438', '10.1002/HED.25547', '10.3390/IJMS20092260', '10.1002/JBM.A.36581', '10.1111/MYC.12931', '10.1073/PNAS.1913491116', '10.1126/SCITRANSLMED.AAS9917', '10.1096/FJ.201801778RR', '10.1007/S10021-018-0301-X', '10.1111/FWB.13209', '10.1093/GIGASCIENCE/GIY134', '10.1016/J.PSYNEUEN.2018.02.021', '10.1016/J.CELREP.2018.03.088', '10.1021/ACS.MOLPHARMACEUT.7B00853', '10.1038/S41541-018-0091-3', '10.1093/RHEUMATOLOGY/KEX456', '10.2967/JNUMED.117.196279', '10.1111/EEA.12682', '10.1016/J.BBR.2016.12.023', '10.1016/J.BBR.2017.02.044', '10.1080/15476286.2017.1325067', '10.1016/J.BBABIO.2016.12.004', '10.1016/J.EJCB.2016.12.005', '10.1177/0022034516679136', '10.1073/PNAS.1619011114', '10.3391/AI.2017.12.3.01', '10.1016/J.CELREP.2016.01.037', '10.1038/EJHG.2015.282', '10.1016/J.AJPATH.2015.11.015', '10.1152/AJPRENAL.00429.2015', '10.4269/AJTMH.16-0226', '10.1128/AAC.01580-16', '10.1111/CMI.12517', '10.1186/S13550-016-0218-3', '10.1002/TERM.1840', '10.1007/S11307-016-0936-Y', '10.1016/J.NANO.2016.06.013', '10.1038/SREP21906', '10.1038/SREP20440', '10.1038/SREP18780', '10.1016/J.BAAE.2016.01.008', '10.1111/1758-2229.12407', '10.1111/JFB.12989', '10.1007/S00227-016-2926-7', '10.14302/ISSN.2470-5020.JNRT-15-800', '10.1152/AJPRENAL.00240.2014', '10.1128/AAC.03850-14', '10.1002/EJI.201545642', '10.1016/J.EJPB.2015.04.020', '10.1016/J.IJPHARM.2015.08.090', '10.1111/JCMM.12526', '10.1016/J.JCONREL.2015.04.019', '10.1002/PATH.4593', '10.1186/S12936-015-0972-0', '10.1089/TEN.TEA.2014.0151', '10.1111/FWB.12550', '10.1007/S10886-015-0601-Y']\n"
     ]
    }
   ],
   "source": [
    "# Filter where results == True\n",
    "filtered = tab[tab['result'] == True]\n",
    "\n",
    "# Find duplicated DOIs within that subset\n",
    "not_unique_dois = (\n",
    "    filtered.loc[filtered['DOI'].duplicated(keep=False), 'DOI']\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af03922d-68e4-4a96-b628-8af2e2ea1792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique DOIs: 42049\n"
     ]
    }
   ],
   "source": [
    "# Count unique values\n",
    "unique_count = output['DOI'].nunique()\n",
    "print(\"Number of unique DOIs:\", unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11c0ee2a-93a6-4edd-8ee5-b2ca24eba79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing methods\n",
    "with open(\"azure/batches/missing_methods_20250920-0843.txt\", \"r\") as f:\n",
    "    missing = f.read().splitlines() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e85c62e4-9f18-40e5-9217-6f8dd5ee4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame and 'missing' is a list of DOIs\n",
    "filtered_df = tab[tab['DOI'].isin(missing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b3cd5f6e-b22e-44c2-9c87-ef12c951e986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jaar uitgave\n",
       "2015    193\n",
       "2016    163\n",
       "2017    132\n",
       "2018    119\n",
       "2019     60\n",
       "2020     33\n",
       "2021     32\n",
       "2024     23\n",
       "2022     20\n",
       "2023     17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Jaar uitgave'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
